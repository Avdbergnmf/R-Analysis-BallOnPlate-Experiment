### Options

#### Dependent Variable
```{r}
selectizeInput("depVar", "Dependent variable",
  choices = NULL, selected = NULL, multiple = FALSE
)

selectizeInput("depVarTransform", "Transform dependent variable",
  choices = c("None" = "none", "Log10" = "log10", "Logit" = "logit"),
  selected = "none", multiple = FALSE
)
```

```{r}
tags$hr(style = "margin-top: 10px; margin-bottom: 10px;")
```

#### Independent Variables
```{r}
selectizeInput("indepInterVars", "Independent variable(s) (interactions)",
  choices = NULL, selected = NULL, multiple = TRUE
)

selectizeInput("indepVars", "Independent variable(s) (add to model)",
  choices = NULL, selected = NULL, multiple = TRUE
)
```

```{r}
tags$hr(style = "margin-top: 10px; margin-bottom: 10px;")
```

#### Data Options
```{r}
checkboxInput("getSummarizedData_stats", "Use summarized data", value = TRUE)
checkboxInput("averageData_stats", "Average data across condition", value = FALSE)
checkboxInput("diffData_stats", "Calculate difference + means per participant", value = FALSE)
```

```{r}
tags$hr(style = "margin-top: 10px; margin-bottom: 10px;")
```

#### Model Settings
```{r}
textInput("customModel", "Custom Model Formula: dependent_variable ~ ", value = "condition * phase + (1 + taskNum | participant)")

checkboxInput("useCustomModel", "Use custom model (above)", value = TRUE)
checkboxInput("doCentering", "Center numerical variables", value = TRUE)
checkboxInput("doScaling", "Also scale (standardize) variables", value = FALSE)

selectizeInput("correctionMethod", "Multiple comparison correction (fixed effects)",
  choices = general_correction_choices,
  selected = "holm", multiple = FALSE
)
```

```{r}
tags$hr(style = "margin-top: 10px; margin-bottom: 10px;")
```

#### Reference Levels
```{r}
selectizeInput("refLevelCondition", "Reference level for condition",
  choices = NULL, selected = NULL, multiple = FALSE
)

selectizeInput("refLevelPhase", "Reference level for phase",
  choices = NULL, selected = NULL, multiple = FALSE
)
```

```{r}
bsTooltip("depVarTransform",
  "Apply transformation to the dependent variable before analysis. Log10 transformation can help with skewed data. Logit transformation is for proportions (values between 0 and 1).",
  placement = "right",
  trigger = "hover"
)
bsTooltip("refLevelCondition",
  "Select the reference level (baseline) for condition comparisons. Other conditions will be compared against this level. Auto-selects the default from initialization.R.",
  placement = "right",
  trigger = "hover"
)
bsTooltip("refLevelPhase",
  "Select the reference level (baseline) for phase comparisons. Other phases will be compared against this level. Auto-selects the default from initialization.R.",
  placement = "right",
  trigger = "hover"
)
bsTooltip("indepInterVars",
  "These independent variables are also multiplied with eachother (including the interaction terms).",
  placement = "right",
  trigger = "hover"
)
bsTooltip("indepVars",
  "These independent variables are not multiplied with eachother.",
  placement = "right",
  trigger = "hover"
)
```

```{r}
bsTooltip("averageData_stats",
  "Make sure to do this when looking at questionnaire data as the dependent variable.",
  placement = "right",
  trigger = "hover"
)
```

```{r}
bsTooltip("force_posthoc",
  "When checked, post-hoc tests will be performed for all effects, not just significant ones.",
  placement = "right",
  trigger = "hover"
)
```

```{r}
bsTooltip("filter_posthoc",
  "When checked, only shows comparisons where at least one level matches between groups (e.g., same condition or same phase).",
  placement = "right",
  trigger = "hover"
)
```

Column
--------------------------------------------

### Statistics Results  {data-height=500}
In this page we ran all of our statistical tests. Select the data in the sidebar, and choose the test settings in the options on the left. Be sure to check the assumptions of the test below. Using the custom formula box disables use of the other independent variable selection boxes.
```{r}
# verbatimTextOutput("stats_results")
uiOutput("stats_results_ui")
```

### LMM EXTRA

#### Tables (for LMM)

##### Fixed effects {data-height=500}

```{r}
uiOutput("lmm_assumption_button_ui")
```

```{r}
# Static PCA button - no reactive dependencies
uiOutput("pca_button_ui")
```

```{r}
tableOutput("fixed_effects_table")
```

##### Random effects {data-height=500}
```{r}
tableOutput("random_effects_table")
```

##### Post-hoc tests {data-height=500}

```{r}
checkboxInput("force_posthoc", "Force Post-Hoc Analysis (show all effects)", value = TRUE)
checkboxInput("filter_posthoc", "Filter Post-Hoc Results (show only meaningful comparisons)", value = TRUE)
checkboxInput("paired_ttest", "Use Paired t-test instead of emmeans", value = FALSE)
```

```{r}
conditionalPanel(
  condition = "input.paired_ttest == true",
  numericInput("num_tests",
    label = "Number of Comparisons (for Bonferroni correction):",
    value = 1, # Default value
    min = 1
  ), # Minimum value (must be at least one test)
  helpText("Click 'Check assumptions' in the table below to inspect diagnostics for each paired comparison.")
)
```

```{r}
conditionalPanel(
  condition = "input.paired_ttest == false",
  selectizeInput("posthoc_correction", "Post-hoc correction method",
    choices = c("tukey", "scheffe", "sidak", general_correction_choices),
    selected = "tukey", multiple = FALSE
  ),
  helpText("Tukey's HSD is recommended for pairwise comparisons. Other methods may be more or less conservative.")
)
```

```{r}
uiOutput("did_button_ui")
```

```{r}
tableOutput("post_hoc_table")
```

```{r, context="server"}
# Create stats page logger
stats_page_logger <- create_module_logger("STATS-PAGE")

# Reactive values for t-test assumption checking
ttest_assumption_lookup <- reactiveVal(list())
ttest_assumption_state <- reactiveVal(NULL)

############ Getting and setting data
get_stats_data <- reactive({
  stats_page_logger("DEBUG", "Getting stats data...")

  # Get the data based on user selection
  data <- if (input$getSummarizedData_stats) {
    stats_page_logger("DEBUG", "Using summarized data (get_mu_dyn_long)")
    get_mu_dyn_long()
  } else {
    stats_page_logger("DEBUG", "Using filtered parameters data")
    filteredParams()
  }

  stats_page_logger("DEBUG", "Raw data dimensions:", nrow(data), "x", ncol(data))

  # Handle empty data case
  if (!stats$validate_stats_data(data)) {
    stats_page_logger("WARN", "Invalid data detected, returning empty dataset")
    return(stats$handle_invalid_data())
  }

  # Apply reference levels so the column names match what the selectors expect
  dt <- stats$prepare_stats_dataset(data, input$averageData_stats)
  stats_page_logger("DEBUG", "Processed data dimensions:", nrow(dt), "x", ncol(dt))
  dt
})

# Helper that tells whether a dependent variable is selected AND exists in data
dep_var_valid <- reactive({
  data <- get_stats_data()
  stats$validate_dependent_variable(input$depVar, data)
})

# Create dynamic observers for variable selection
create_dynamic_variable_observer(
  data_reactive = get_stats_data,
  input_id = "depVar",
  column_filter = function(x) TRUE, # All columns
  exclude_patterns = NULL,
  default_choice = "task.dist_to_escape_ratio_mean", # "stepWidths.sd",
  fallback_choices = NULL,
  multiple = FALSE,
  input = input
)

# Default variables more appropriate for the current experiment
defaultIndepVars <- c("condition")

create_dynamic_variable_observer(
  data_reactive = get_stats_data,
  input_id = "indepInterVars",
  column_filter = function(x) TRUE, # All columns
  exclude_patterns = NULL,
  default_choice = defaultIndepVars,
  fallback_choices = NULL,
  multiple = TRUE,
  input = input
)

create_dynamic_variable_observer(
  data_reactive = get_stats_data,
  input_id = "indepVars",
  column_filter = function(x) TRUE, # All columns
  exclude_patterns = NULL,
  default_choice = defaultIndepVars,
  fallback_choices = NULL,
  multiple = TRUE,
  input = input
)

# Dynamic observers for reference level selection
observe({
  data <- get_stats_data()
  stats_page_logger("DEBUG", "Updating reference level selectors...")

  if ("condition" %in% names(data)) {
    available_conditions <- unique(data$condition)
    stats_page_logger("DEBUG", "Available conditions:", paste(available_conditions, collapse = ", "))

    # Get default from reference_levels or use first value
    default_ref <- if (exists("reference_levels") && "condition" %in% names(reference_levels)) {
      ref <- reference_levels$condition
      if (ref %in% available_conditions) ref else available_conditions[1]
    } else {
      available_conditions[1]
    }

    stats_page_logger("DEBUG", "Setting condition reference level to:", default_ref)
    updateSelectizeInput(session, "refLevelCondition",
      choices = available_conditions,
      selected = default_ref
    )
  }

  if ("phase" %in% names(data)) {
    available_phases <- unique(data$phase)
    stats_page_logger("DEBUG", "Available phases:", paste(available_phases, collapse = ", "))

    # Get default from reference_levels or use first value
    default_ref <- if (exists("reference_levels") && "phase" %in% names(reference_levels)) {
      ref <- reference_levels$phase
      if (ref %in% available_phases) ref else available_phases[1]
    } else {
      available_phases[1]
    }

    stats_page_logger("DEBUG", "Setting phase reference level to:", default_ref)
    updateSelectizeInput(session, "refLevelPhase",
      choices = available_phases,
      selected = default_ref
    )
  }
})

# ----------------  APPLY MODEL  ----------------
get_lmer <- reactive({
  req(dep_var_valid()) # ← stop early but quietly if no dep-var
  stats_page_logger("INFO", "Building LMM model...")

  data <- get_stats_data()
  stats_page_logger("DEBUG", "Model data dimensions:", nrow(data), "x", ncol(data))
  # Validation is now handled in fit_mixed_model

  # Apply custom reference levels if specified
  if (!is.null(input$refLevelCondition) && nzchar(input$refLevelCondition)) {
    stats_page_logger("DEBUG", "Setting condition reference level to:", input$refLevelCondition)
    data <- stats$set_reference_level(data, "condition", input$refLevelCondition)
  }
  if (!is.null(input$refLevelPhase) && nzchar(input$refLevelPhase)) {
    stats_page_logger("DEBUG", "Setting phase reference level to:", input$refLevelPhase)
    data <- stats$set_reference_level(data, "phase", input$refLevelPhase)
  }

  # Apply transformation to dependent variable if selected
  if (input$depVarTransform != "none") {
    stats_page_logger("DEBUG", "Applying transformation:", input$depVarTransform, "to", input$depVar)
  }
  data <- stats$transform_dependent_variable(data, input$depVar, input$depVarTransform)
  if (is.null(data)) {
    stats_page_logger("ERROR", "Data transformation failed")
    return(NULL)
  }

  doCustom <- input$useCustomModel && !is.null(input$customModel) && nzchar(input$customModel)
  if (doCustom) {
    stats_page_logger("INFO", "Using custom model formula:", input$customModel)
    formula <- as.formula(paste(input$depVar, "~", input$customModel))
  } else {
    stats_page_logger(
      "INFO", "Using standard LMM formula with variables:",
      paste(c(input$indepInterVars, input$indepVars), collapse = ", ")
    )
    formula <- stats$create_lmm_formula(input$depVar, input$indepInterVars, input$indepVars)
  }

  # Centering is now handled in fit_mixed_model
  stats_page_logger("INFO", "Fitting mixed model...")
  result <- stats$fit_mixed_model(data, formula, input$depVar, input$doCentering, input$doScaling)

  if (is.null(result)) {
    stats_page_logger("ERROR", "Model fitting failed")
  } else {
    stats_page_logger("INFO", "Model fitted successfully")
  }

  result
})

# ----------------  LMM OUTPUTS ----------------
output$stats_results_ui <- renderUI({
  verbatimTextOutput("lmm_text")
})

output$lmm_text <- renderPrint({
  lmm <- get_lmer()
  if (is.null(lmm)) {
    cat("Model could not be fitted. Check for errors above.\n")
    return()
  }

  results <- summary(lmm)

  # Show reference level information
  cat("REFERENCE LEVELS:\n")
  if (!is.null(input$refLevelCondition) && nzchar(input$refLevelCondition)) {
    cat("Condition reference level:", input$refLevelCondition, "\n")
  }
  if (!is.null(input$refLevelPhase) && nzchar(input$refLevelPhase)) {
    cat("Phase reference level:", input$refLevelPhase, "\n")
  }
  cat("\n")

  # Show transformation information
  if (input$depVarTransform != "none") {
    cat("TRANSFORMATION APPLIED:\n")
    cat("Dependent variable transformation:", input$depVarTransform, "\n")
    cat("Note: All results are based on the transformed variable.\n\n")
  }

  # Summarize the model
  cat("\nLMM:\n")
  print(lmm)
  cat("\nRESULTS:\n")
  print(results)

  # Print AIC and BIC
  aic_value <- AIC(lmm)
  bic_value <- BIC(lmm)
  log_likelihood <- logLik(lmm)
  deviance <- deviance(lmm)
  r_squared <- MuMIn::r.squaredGLMM(lmm)

  cat("\nModel fit statistics:\n")
  cat("AIC:", aic_value, "\n")
  cat("BIC:", bic_value, "\n")
  cat("Log-likelihood:", log_likelihood, "\n")
  cat("Deviance:", deviance, "\n")
  cat("Marginal R-squared:", r_squared[1], "\n")
  cat("Conditional R-squared:", r_squared[2], "\n")

  # Add interpretation guidance for model fit statistics
  cat("\nModel Fit Interpretation:\n")
  cat("- AIC (Akaike Information Criterion): Lower values indicate better model fit\n")
  cat("- BIC (Bayesian Information Criterion): Lower values indicate better model fit\n")
  cat("- Log-likelihood: Higher values indicate better model fit\n")
  cat("- Deviance: Lower values indicate better model fit\n")
  cat("- R-squared: Higher values indicate more variance explained by the model\n")
  cat("  * Marginal R-squared: Variance explained by fixed effects only\n")
  cat("  * Conditional R-squared: Variance explained by both fixed and random effects\n")

  # Calculate and print VIF
  cat("\nVariance Inflation Factors (VIF):\n")
  tryCatch(
    {
      vif_values <- car::vif(lmm)
      print(vif_values)
    },
    error = function(e) {
      cat("VIF calculation failed:", e$message, "\n")
    }
  )

  cat("\nChecking Singularity:...\n")
  cat("isSingular:", isSingular(lmm, tol = 1e-4), "\n")
})

output$fixed_effects_table <- renderTable(
  {
    req(dep_var_valid()) # skip rendering until ready
    lmm <- get_lmer()
    results <- summary(lmm)
    fixed_effects <- results$coefficients

    # Calculate effect sizes
    residual_sd <- sigma(lmm)
    fixed_effects_df <- as.data.frame(fixed_effects)
    fixed_effects_df$EffectSize <- fixed_effects_df$Estimate / residual_sd

    # Adjust p-values for multiple comparisons using the selected correction method
    fixed_effects_df$AdjustedP <- p.adjust(fixed_effects_df[["Pr(>|t|)"]], method = input$correctionMethod)

    # Convert to a data frame for rendering and include row names
    fixed_effects_df <- cbind(Effect = rownames(fixed_effects_df), fixed_effects_df)
    rownames(fixed_effects_df) <- NULL

    # Format numbers and make significant p-values bold
    fixed_effects_df <- stats$format_with_bold_pvalues(fixed_effects_df, "AdjustedP")

    fixed_effects_df
  },
  rownames = TRUE,
  sanitize.text.function = function(x) x
)


output$random_effects_table <- renderTable(
  {
    req(dep_var_valid())
    lmm <- get_lmer()
    random_effects <- as.data.frame(VarCorr(lmm))

    # Clean up the random effects table
    random_effects_df <- cbind(Effect = rownames(random_effects), random_effects)
    rownames(random_effects_df) <- NULL

    # Select only relevant columns
    random_effects_df <- random_effects_df[, c("Effect", "grp", "vcov", "sdcor")]

    # Optionally rename columns for clarity
    colnames(random_effects_df) <- c("Effect", "Group", "Variance", "Standard Deviation")

    random_effects_df <- stats$format_numeric_columns(random_effects_df)

    random_effects_df
  },
  rownames = TRUE
)

output$post_hoc_table <- renderTable(
  {
    req(dep_var_valid())
    lmm <- get_lmer()

    # Get the same processed data that was used for the model
    data <- get_stats_data()

    # Apply same reference levels as in get_lmer()
    if (!is.null(input$refLevelCondition) && nzchar(input$refLevelCondition)) {
      data <- stats$set_reference_level(data, "condition", input$refLevelCondition)
    }
    if (!is.null(input$refLevelPhase) && nzchar(input$refLevelPhase)) {
      data <- stats$set_reference_level(data, "phase", input$refLevelPhase)
    }

    # Apply same transformation as in get_lmer()
    data <- stats$transform_dependent_variable(data, input$depVar, input$depVarTransform)
    if (is.null(data)) {
      return(data.frame(Message = "Transformation failed. Cannot perform post-hoc analysis."))
    }

    # Prepare analysis (use posthoc_correction for emmeans, not correctionMethod which is for fixed effects)
    posthoc_results <- stats$run_posthoc_analysis(lmm, data, input$indepInterVars, input$indepVars, input$force_posthoc, input$posthoc_correction)
    if (is.null(posthoc_results$results)) {
      return(data.frame(Message = "No significant main or interaction effects found."))
    }

    # Create lmm_posthoc structure for compatibility with existing code
    lmm_posthoc <- list(
      combined = list(df = posthoc_results$results),
      posthoc_results = posthoc_results$metadata$posthoc_results,
      all_indep_vars = posthoc_results$metadata$all_indep_vars
    )

    # Choose method based on paired_ttest input
    if (input$paired_ttest) {
      res <- stats$run_paired_ttest_analysis(lmm_posthoc, data, input$depVar, input$num_tests)

      # Store assumption lookup data and add assumption buttons
      assumption_lookup <- attr(res, "assumption_lookup")
      ttest_assumption_lookup(assumption_lookup)

      # Add assumption check buttons if we have valid results and remove AssumptionID
      if (!"Message" %in% names(res)) {
        if ("AssumptionID" %in% names(res)) {
          assumption_ids <- res$AssumptionID
          res$AssumptionID <- NULL # Remove ID column from display
          res$Assumptions <- sapply(assumption_ids, stats$create_assumption_button)
        }
      }
    } else {
      res <- lmm_posthoc$combined$df
    }

    p_format_names <- c("p_value", "p.value", "corrected_p") # what column names to format based on value < 0.05
    # Note: postprocess_posthoc_results is called internally by run_posthoc_analysis
    res
  },
  sanitize.text.function = function(x) x,
  escape = FALSE
)

# T-test assumption checking observer
observeEvent(input$ttest_assumption_row, {
  stats_page_logger("INFO", "T-test assumption checking for row:", input$ttest_assumption_row)

  lookup <- ttest_assumption_lookup()
  info <- lookup[[input$ttest_assumption_row]]
  if (is.null(info)) {
    stats_page_logger("ERROR", "Assumption diagnostics unavailable for row:", input$ttest_assumption_row)
    if (exists("showNotification")) {
      showNotification("Assumption diagnostics unavailable for this comparison.", type = "error")
    }
    return()
  }

  stats_page_logger("DEBUG", "Showing assumption diagnostics for:", info$effect, "-", info$contrast)
  ttest_assumption_state(info)

  showModal(modalDialog(
    title = "Paired t-test assumption diagnostics",
    uiOutput("ttest_assumption_details"),
    plotOutput("ttest_assumption_hist", height = 250),
    plotOutput("ttest_assumption_qq", height = 250),
    plotOutput("ttest_assumption_box", height = 250),
    size = "l",
    easyClose = TRUE,
    footer = modalButton("Close")
  ))
})

# DiD button UI
output$did_button_ui <- renderUI({
  req(dep_var_valid())
  HTML(stats$create_did_button())
})

# LMM assumption button
output$lmm_assumption_button_ui <- renderUI({
  req(dep_var_valid())
  HTML(stats$create_lmm_assumption_button())
})

# PCA button UI - using proper Shiny actionButton
output$pca_button_ui <- renderUI({
  stats_page_logger("DEBUG", "Rendering PCA button...")
  actionButton("show_pca_analysis",
    "Run PCA Analysis",
    class = "btn-primary",
    style = "margin-top: 10px;",
    icon = icon("chart-line")
  )
})

# Test observer to see if button clicks are being registered at all
observeEvent(input$show_pca_analysis,
  {
    stats_page_logger("INFO", "PCA button click detected!")
  },
  ignoreInit = TRUE
)

# PCA analysis observer
observeEvent(input$show_pca_analysis, {
  stats_page_logger("INFO", "PCA button clicked! Starting PCA analysis...")

  data <- get_stats_data()
  stats_page_logger("INFO", "Data retrieved. Dimensions:", nrow(data), "x", ncol(data))

  if (is.null(data) || nrow(data) == 0) {
    stats_page_logger("ERROR", "No data available")
    showNotification("No data available for PCA analysis.", type = "error")
    return()
  }

  # Get available variables
  stats_page_logger("INFO", "Getting available variables...")
  available_vars <- stats$get_pca_variables(data)
  stats_page_logger("INFO", "Available variables:", length(available_vars), "variables found")
  stats_page_logger("DEBUG", "Variables:", paste(available_vars, collapse = ", "))

  if (length(available_vars) < 2) {
    stats_page_logger("ERROR", "Not enough variables (", length(available_vars), ")")
    showNotification("Need at least 2 numeric variables for PCA analysis.", type = "warning")
    return()
  }

  # Show variable selection modal first
  stats_page_logger("INFO", "Showing variable selection modal...")
  showModal(modalDialog(
    title = "Select Variables for PCA Analysis",
    tags$div(
      tags$p("Select variables for PCA analysis. Use the string input below to add/remove variables by name pattern."),
      tags$hr(),

      # String input for variable selection
      textInput("pca_string",
        "Variable name pattern:",
        placeholder = "e.g., 'task', '_sd', 'task AND _sd', 'task OR step', '!_sd'",
        width = "100%"
      ),

      # Action buttons
      tags$div(
        tags$h5("Actions:"),
        tags$div(
          actionButton("add_vars_by_string", "Add Variables", class = "btn-primary", style = "margin: 2px;"),
          actionButton("remove_vars_by_string", "Remove Variables", class = "btn-warning", style = "margin: 2px;"),
          actionButton("add_all_vars", "Add All Variables", class = "btn-success", style = "margin: 2px;"),
          actionButton("clear_all_vars", "Clear All", class = "btn-danger", style = "margin: 2px;")
        )
      ),
      tags$hr(),

      # Variable selection display
      selectizeInput("pca_variables",
        "Selected variables:",
        choices = available_vars,
        selected = NULL,
        multiple = TRUE,
        options = list(
          placeholder = "No variables selected - use buttons above to add variables"
        )
      ),
      tags$hr(),
      tags$p(tags$strong("Selected:"), textOutput("pca_selected_count", inline = TRUE), "variables")
    ),
    footer = tagList(
      modalButton("Cancel"),
      actionButton("run_pca", "Run PCA Analysis", class = "btn-primary")
    ),
    size = "l"
  ))
  stats_page_logger("INFO", "Modal displayed successfully")
})

# Store available variables for PCA in a reactive value
pca_available_vars <- reactiveVal(NULL)

# Variable selection now handled by stats module

# Update available variables when PCA modal opens
observeEvent(input$show_pca_analysis, {
  data <- get_stats_data()
  available_vars <- stats$get_pca_variables(data)
  pca_available_vars(available_vars)

  # Set default selected variables
  default_vars <- c(
    "task.dist_to_escape_ratio_mean", "complexity.pelvisPos_raw_sd", "complexity.hipPos_raw_sd",
    "questionnaire.IMI.total", "questionnaire.UserExperience.total", "age", "weight", "height_meters",
    "task.n_ball_falls", "task.final_work_world", "task.pAccAbsolute_mean", "task.absqd_mean",
    "task.pVelAbsolute_mean", "task.drop_risk_1s_mean", "task.drop_risk_bin_mean",
    "task.drop_risk_1s_sd", "treadmillSpeed.mean", "task.total_score"
  )

  # Filter to only include variables that are actually available
  selected_defaults <- default_vars[default_vars %in% available_vars]

  # Update the selectizeInput with default selection
  updateSelectizeInput(session, "pca_variables",
    choices = available_vars,
    selected = selected_defaults
  )

  stats_page_logger("INFO", "Set default PCA variables:", length(selected_defaults), "out of", length(default_vars), "requested")
})

# Add variables by string pattern
observeEvent(input$add_vars_by_string, {
  if (is.null(input$pca_string) || nchar(input$pca_string) == 0) {
    showNotification("Please enter a string pattern to search for variables.", type = "warning")
    return()
  }

  current_selected <- input$pca_variables
  matching_vars <- stats$match_variables(input$pca_string, pca_available_vars())
  new_selected <- unique(c(current_selected, matching_vars))
  updateSelectizeInput(session, "pca_variables", selected = new_selected)
  stats_page_logger("INFO", "Added", length(matching_vars), "variables matching pattern '", input$pca_string, "'")
})

# Remove variables by string pattern
observeEvent(input$remove_vars_by_string, {
  if (is.null(input$pca_string) || nchar(input$pca_string) == 0) {
    showNotification("Please enter a string pattern to search for variables.", type = "warning")
    return()
  }

  current_selected <- input$pca_variables
  if (is.null(current_selected) || length(current_selected) == 0) {
    showNotification("No variables selected to remove.", type = "message")
    return()
  }

  matching_vars <- stats$match_variables(input$pca_string, current_selected)
  new_selected <- current_selected[!current_selected %in% matching_vars]
  updateSelectizeInput(session, "pca_variables", selected = new_selected)
  stats_page_logger("INFO", "Removed", length(matching_vars), "variables matching pattern '", input$pca_string, "'")
})

# Add all variables
observeEvent(input$add_all_vars, {
  updateSelectizeInput(session, "pca_variables", selected = pca_available_vars())
  stats_page_logger("INFO", "Added all", length(pca_available_vars()), "variables")
})

# Clear all variables
observeEvent(input$clear_all_vars, {
  stats_page_logger("INFO", "Clear all button clicked")
  updateSelectizeInput(session, "pca_variables", selected = character(0))
  stats_page_logger("INFO", "Cleared all selected variables")
})

# Display count of selected variables
output$pca_selected_count <- renderText({
  if (is.null(input$pca_variables)) {
    "0"
  } else {
    length(input$pca_variables)
  }
})

# Run PCA analysis after variable selection
observeEvent(input$run_pca, {
  stats_page_logger("INFO", "Run PCA button clicked! Starting analysis...")

  data <- get_stats_data()
  stats_page_logger("INFO", "Data retrieved for PCA analysis. Dimensions:", nrow(data), "x", ncol(data))

  # Get selected variables (NULL means use all)
  selected_vars <- input$pca_variables
  if (length(selected_vars) == 0) {
    selected_vars <- NULL
    stats_page_logger("INFO", "No variables selected, will use all numeric variables")
  } else {
    stats_page_logger("INFO", "Selected variables:", length(selected_vars), "variables")
    stats_page_logger("DEBUG", "Selected variables:", paste(selected_vars, collapse = ", "))
  }

  # Run PCA analysis
  stats_page_logger("INFO", "Running PCA analysis...")
  pca_results <- stats$run_pca_analysis(data, selected_vars)

  # Check for errors
  if (!is.null(pca_results$error)) {
    stats_page_logger("ERROR", "PCA analysis failed:", pca_results$error)

    # Provide more helpful error messages
    error_msg <- pca_results$error
    if (grepl("Not enough complete cases", error_msg)) {
      error_msg <- paste(
        error_msg,
        "\n\nTip: Try selecting fewer variables or check for missing data. With many variables relative to observations, you may need to select a subset of the most relevant variables."
      )
    }

    showNotification(error_msg, type = "error", duration = 15)
    removeModal()
    return()
  }

  stats_page_logger("INFO", "PCA analysis completed successfully")

  # Close variable selection modal
  removeModal()

  # Show results modal
  showModal(
    modalDialog(
      tags$head(tags$style(HTML("
        .modal-dialog { max-width: 95%; width: 95%; }
        .modal-body { overflow-x: auto; }
      "))),
      title = "Principal Component Analysis Results",
      tags$div(
        tags$h4("Overview:"),
        tags$p("Principal Component Analysis (PCA) reduces the dimensionality of your data by finding the principal components that explain the most variance."),
        tags$p(tags$strong("Number of observations:"), pca_results$metadata$n_observations),
        tags$p(tags$strong("Number of variables:"), pca_results$metadata$n_variables),
        if (pca_results$metadata$excluded_rows > 0) {
          tags$p(tags$em(paste("Note:", pca_results$metadata$excluded_rows, "rows with missing data were excluded.")))
        },
        tags$hr(),

        # Summary statistics
        tags$h4("Variance Explained by Components:"),
        tags$p(paste("Components needed for 80% variance:", pca_results$summary_stats$n_components_80_percent)),
        tags$p(paste("Components needed for 95% variance:", pca_results$summary_stats$n_components_95_percent)),
        renderTable({
          head(pca_results$summary_stats$summary_table, 10)
        }),
        tags$hr(),

        # Scree plot
        tags$h4("Scree Plot:"),
        tags$p("Shows the proportion of variance explained by each principal component. Look for the 'elbow' to determine how many components to retain."),
        renderPlot(
          {
            print(pca_results$plot_scree)
          },
          height = 400
        ),
        tags$hr(),

        # Correlation matrix
        tags$h4("Correlation Matrix:"),
        tags$p("Shows correlations between all variables. Strong correlations (red/blue) indicate redundancy that PCA can capture."),
        renderPlot(
          {
            print(pca_results$cor_matrix_plot)
          },
          height = 500
        ),
        tags$hr(),

        # Biplot
        tags$h4("Principal Components Biplot (PC1 vs PC2):"),
        tags$p("Each point represents an observation projected onto the first two principal components."),
        renderPlot(
          {
            print(pca_results$PCA12)
          },
          height = 500
        ),
        tags$hr(),

        # Factor loadings
        tags$h4("Factor Loadings (PC1 and PC2):"),
        tags$p("Shows how much each variable contributes to PC1 and PC2. Variables with high loadings are important for that component."),
        renderPlot(
          {
            print(pca_results$PlotLoadings)
          },
          height = 600
        ),
        tags$hr(),

        # Interpretation guide
        tags$h4("How to Interpret:"),
        tags$ul(
          tags$li(tags$strong("Scree Plot:"), " Components before the 'elbow' are typically retained."),
          tags$li(tags$strong("Loadings:"), " High absolute values indicate variables that contribute strongly to that component."),
          tags$li(tags$strong("Biplot:"), " Clusters of points suggest groups with similar characteristics."),
          tags$li(tags$strong("PC1:"), " Captures the most variance in the data."),
          tags$li(tags$strong("PC2:"), " Captures the second most variance, orthogonal to PC1.")
        )
      ),
      size = "l",
      easyClose = TRUE,
      footer = modalButton("Close")
    )
  )
})

# DiD analysis observer
observeEvent(input$show_did_analysis, {
  req(dep_var_valid())
  stats_page_logger("INFO", "DiD analysis button clicked!")

  lmm <- get_lmer()
  data <- get_stats_data()

  if (is.null(lmm)) {
    stats_page_logger("ERROR", "Model could not be fitted for DiD analysis")
    if (exists("showNotification")) {
      showNotification("Model could not be fitted. Please check your model settings.", type = "error")
    }
    return()
  }

  # Compute DiD analysis (uses Kenward-Roger df and selected correction method)
  stats_page_logger("INFO", "Running DiD analysis with correction method:", input$correctionMethod)
  did_results <- stats$run_did_analysis(lmm, data, input$correctionMethod)

  # Check if we have valid results
  if (!is.null(did_results$message)) {
    showNotification(did_results$message, type = "warning", duration = 10)
    return()
  }

  # Format the results for display
  within_cond_display <- did_results$within_condition
  within_phase_display <- did_results$within_phase
  did_display <- did_results$did
  baseline_used <- did_results$baseline_used

  if (!is.null(within_cond_display)) {
    within_cond_display <- stats$format_with_bold_pvalues(within_cond_display, "p_adjusted", digits = 4)
  }
  if (!is.null(within_phase_display)) {
    within_phase_display <- stats$format_with_bold_pvalues(within_phase_display, "p_adjusted", digits = 4)
  }
  if (!is.null(did_display)) {
    did_display <- stats$format_with_bold_pvalues(did_display, "p_adjusted", digits = 4)
  }

  # Show modal with results
  showModal(
    modalDialog(
      tags$head(tags$style(HTML("
        .modal-dialog { max-width: 90%; width: 90%; }
        .modal-body { overflow-x: auto; }
      "))),
      title = "Difference-in-Differences (DiD) Analysis",
      tags$div(
        tags$h4("Overview:"),
        tags$p("This analysis compares how changes from baseline phase differ between conditions."),
        tags$p(tags$strong("Baseline phase used:"), baseline_used),
        tags$hr(),
        tags$h5("Statistical Methods:"),
        tags$ul(
          tags$li(tags$strong("Degrees of Freedom:"), " Kenward-Roger approximation (more accurate for small samples and complex random effects structures)"),
          tags$li(tags$strong("Multiple Comparison Correction:"), paste("Selected method:", input$correctionMethod)),
          tags$li(tags$strong("Confidence Intervals:"), " 95% CIs based on the t-distribution with Kenward-Roger df")
        ),
        tags$h5("Interpreting Estimates:"),
        tags$ul(
          tags$li(tags$strong("Within-Condition:"), " Positive = increase from baseline; Negative = decrease from baseline"),
          tags$li(tags$strong("Within-Phase:"), " Positive = condition_cmp > condition_ref; Negative = condition_cmp < condition_ref"),
          tags$li(tags$strong("DiD:"), " Positive = condition_cmp changed more (or decreased less) than condition_ref from baseline; Negative = condition_cmp changed less (or decreased more) than condition_ref")
        ),
        tags$p(tags$em("Note: Bold p-values indicate significance at α = 0.05 after correction.")),
        tags$hr()
      ),

      # Within-condition comparisons table
      if (!is.null(within_cond_display)) {
        tags$div(
          tags$h4("Within-Condition Phase Comparisons", style = "margin-top: 20px;"),
          tags$p("Each condition's change from baseline phase (used as inputs for DiD calculation)."),
          renderTable(
            {
              within_cond_display
            },
            sanitize.text.function = function(x) x,
            escape = FALSE
          ),
          tags$hr()
        )
      },

      # DiD results table
      tags$div(
        tags$h4("Difference-in-Differences Results", style = "margin-top: 20px;"),
        tags$p("Tests whether conditions differ in how they changed from baseline to each phase."),
        renderTable(
          {
            did_display
          },
          sanitize.text.function = function(x) x,
          escape = FALSE
        ),
        tags$hr()
      ),

      # Within-phase comparisons table
      if (!is.null(within_phase_display)) {
        tags$div(
          tags$h4("Within-Phase Condition Comparisons", style = "margin-top: 20px;"),
          tags$p("Pairwise comparisons between all conditions within each phase."),
          renderTable(
            {
              within_phase_display
            },
            sanitize.text.function = function(x) x,
            escape = FALSE
          )
        )
      },
      easyClose = TRUE,
      footer = modalButton("Close")
    )
  )
})

# LMM assumption checking observer
observeEvent(input$show_lmm_assumptions, {
  req(dep_var_valid())
  stats_page_logger("INFO", "LMM assumption checking button clicked!")

  showModal(modalDialog(
    title = "Linear Mixed Model (LMM) Assumption Diagnostics",
    tags$div(
      tags$h4("How to interpret these plots:"),
      tags$ul(
        tags$li(tags$strong("QQ Plot:"), " Points should fall approximately along the diagonal line. Deviations suggest non-normal residuals."),
        tags$li(tags$strong("Residuals vs Fitted:"), " Look for random scatter around zero. Patterns suggest heteroscedasticity or non-linearity."),
        tags$li(tags$strong("Scale-Location:"), " Look for a horizontal line with equally spread points. Deviations suggest non-constant variance (heteroscedasticity)."),
        tags$li(tags$strong("Residuals vs Leverage:"), " Check for influential cases. Points outside Cook's distance lines are potential outliers that may unduly influence the model.")
      ),
      tags$p("For more detailed interpretation, please refer to statistical literature or consult a statistician.")
    ),
    plotOutput("lmm_assumption_qq", height = 250),
    plotOutput("lmm_assumption_residuals_fitted", height = 250),
    plotOutput("lmm_assumption_scale_location", height = 250),
    plotOutput("lmm_assumption_residuals_leverage", height = 250),
    size = "l",
    easyClose = TRUE,
    footer = modalButton("Close")
  ))
})

# LMM assumption modal plots
output$lmm_assumption_qq <- renderPlot({
  req(dep_var_valid())
  lmm <- get_lmer()
  qqnorm(resid(lmm), main = "QQ Plot of Residuals")
  qqline(resid(lmm), col = "blue")
})

output$lmm_assumption_residuals_fitted <- renderPlot({
  req(dep_var_valid())
  lmm <- get_lmer()
  plot(fitted(lmm), resid(lmm),
    xlab = "Fitted values",
    ylab = "Residuals",
    main = "Residuals vs Fitted"
  )
  abline(h = 0, col = "red")
})

output$lmm_assumption_scale_location <- renderPlot({
  req(dep_var_valid())
  lmm <- get_lmer()
  sqrt_resid <- sqrt(abs(resid(lmm)))
  plot(fitted(lmm), sqrt_resid,
    xlab = "Fitted values",
    ylab = "√|Standardized residuals|",
    main = "Scale-Location Plot"
  )
  abline(h = mean(sqrt_resid, na.rm = TRUE), col = "red")
})

output$lmm_assumption_residuals_leverage <- renderPlot({
  req(dep_var_valid())
  lmm <- get_lmer()
  leverage <- hatvalues(lmm)
  cooksd <- cooks.distance(lmm)
  plot(leverage, resid(lmm),
    xlab = "Leverage",
    ylab = "Residuals",
    main = "Residuals vs Leverage"
  )
  abline(h = 0, col = "red")
  # Highlight influential points
  influential <- cooksd > 4 / (length(cooksd) - length(coef(lmm)))
  points(leverage[influential], resid(lmm)[influential], pch = 20, col = "red", cex = 1.2)
})

# Modal content outputs for t-test assumptions
output$ttest_assumption_details <- renderUI({
  info <- ttest_assumption_state()
  req(info)
  tagList(
    tags$div(
      tags$h4("Comparison Details:"),
      tags$p(tags$strong("Effect:"), info$effect),
      tags$p(tags$strong("Contrast:"), info$contrast),
      tags$p(tags$strong("Pairs used:"), info$n_pairs),
      tags$p(
        tags$strong("Levels compared:"),
        sprintf(
          "%s  vs  %s",
          paste(info$left_levels, collapse = " × "),
          paste(info$right_levels, collapse = " × ")
        )
      )
    ),
    tags$div(
      tags$h4("How to interpret these plots:"),
      tags$ul(
        tags$li(tags$strong("Histogram of Differences:"), " Should be roughly symmetric and bell-shaped, centered around zero. Skewness or multiple peaks may indicate violations of normality."),
        tags$li(tags$strong("Q-Q Plot of Differences:"), " Points should fall approximately along the diagonal line (blue). Systematic deviations suggest the differences are not normally distributed."),
        tags$li(tags$strong("Boxplot of Differences:"), " Check for extreme outliers (points beyond the whiskers). Outliers can affect the validity of the paired t-test and should be investigated.")
      ),
      tags$p(tags$strong("Note:"), " The paired t-test assumes that the differences between paired observations are normally distributed. If these assumptions are violated, consider non-parametric alternatives like the Wilcoxon signed-rank test.")
    )
  )
})

output$ttest_assumption_hist <- renderPlot({
  info <- ttest_assumption_state()
  req(info)
  diffs <- info$differences
  if (length(diffs) < 2) {
    plot.new()
    text(0.5, 0.5, "Not enough paired observations\nto plot diagnostics.", cex = 1.1, col = "red")
    return()
  }
  hist(diffs,
    main = "Histogram of Paired Differences",
    xlab = "Differences (Right - Left)", col = "lightblue", border = "white",
    breaks = max(5, min(15, length(diffs) / 3))
  )
  # Add normal curve overlay
  x_seq <- seq(min(diffs), max(diffs), length.out = 100)
  y_seq <- dnorm(x_seq, mean(diffs), sd(diffs))
  y_seq <- y_seq * length(diffs) * diff(range(diffs)) / length(x_seq)
  lines(x_seq, y_seq, col = "red", lwd = 2)
})

output$ttest_assumption_qq <- renderPlot({
  info <- ttest_assumption_state()
  req(info)
  diffs <- info$differences
  if (length(diffs) < 2) {
    plot.new()
    text(0.5, 0.5, "Not enough paired observations\nto plot diagnostics.", cex = 1.1, col = "red")
    return()
  }
  qqnorm(diffs, main = "Q-Q Plot of Differences")
  qqline(diffs, col = "blue", lwd = 2)
})

output$ttest_assumption_box <- renderPlot({
  info <- ttest_assumption_state()
  req(info)
  diffs <- info$differences
  if (length(diffs) < 2) {
    plot.new()
    text(0.5, 0.5, "Not enough paired observations\nto plot diagnostics.", cex = 1.1, col = "red")
    return()
  }
  boxplot(diffs,
    main = "Boxplot of Differences",
    ylab = "Differences (Right - Left)",
    col = "lightblue", border = "darkblue"
  )
  abline(h = 0, col = "red", lty = 2)
  # Add mean line
  abline(h = mean(diffs), col = "green", lwd = 2)
  legend("topright", c("Zero line", "Mean"),
    col = c("red", "green"),
    lty = c(2, 1), lwd = c(1, 2), cex = 0.8
  )
})
```

