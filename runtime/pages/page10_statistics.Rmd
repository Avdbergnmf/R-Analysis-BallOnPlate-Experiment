### Options

```{r}
selectizeInput("depVar", "Dependent variable",
  choices = NULL, selected = NULL, multiple = FALSE
)

selectizeInput("depVarTransform", "Transform dependent variable",
  choices = c("None" = "none", "Log10" = "log10"),
  selected = "none", multiple = FALSE
)

selectizeInput("indepInterVars", "Independent variable(s) (interactions)",
  choices = NULL, selected = NULL, multiple = TRUE
)

selectizeInput("indepVars", "Independent variable(s) (add to model)",
  choices = NULL, selected = NULL, multiple = TRUE
)

checkboxInput("getSummarizedData_stats", "Use summarized data", value = TRUE)
checkboxInput("averageData_stats", "Average data across condition", value = FALSE)
checkboxInput("diffData_stats", "Calculate difference + means per participant", value = FALSE)

textInput("customModel", "Custom Model Formula: dependent_variable ~ ", value = "condition * phase + (1 | participant)")

checkboxInput("useCustomModel", "Use custom model (above)", value = TRUE)
checkboxInput("doCentering", "Center numerical variables", value = TRUE)
checkboxInput("doScaling", "Also scale (standardize) variables", value = FALSE)

selectizeInput("correctionMethod", "Multiple comparison correction (fixed effects)",
  choices = c("holm", "hochberg", "hommel", "bonferroni", "BH", "BY", "fdr", "none"),
  selected = "holm", multiple = FALSE
)
```

```{r}
bsTooltip("depVarTransform",
  "Apply transformation to the dependent variable before analysis. Log10 transformation can help with skewed data.",
  placement = "right",
  trigger = "hover"
)
bsTooltip("indepInterVars",
  "These independent variables are also multiplied with eachother (including the interaction terms).",
  placement = "right",
  trigger = "hover"
)
bsTooltip("indepVars",
  "These independent variables are not multiplied with eachother.",
  placement = "right",
  trigger = "hover"
)
```

```{r}
bsTooltip("averageData_stats",
  "Make sure to do this when looking at questionnaire data as the dependent variable.",
  placement = "right",
  trigger = "hover"
)
```

```{r}
bsTooltip("force_posthoc",
  "When checked, post-hoc tests will be performed for all effects, not just significant ones.",
  placement = "right",
  trigger = "hover"
)
```

```{r}
bsTooltip("filter_posthoc",
  "When checked, only shows comparisons where at least one level matches between groups (e.g., same condition or same phase).",
  placement = "right",
  trigger = "hover"
)
```

Column
--------------------------------------------

### Statistics Results  {data-height=500}
In this page we ran all of our statistical tests. Select the data in the sidebar, and choose the test settings in the options on the left. Be sure to check the assumptions of the test below. Using the custom formula box disables use of the other independent variable selection boxes.
```{r}
# verbatimTextOutput("stats_results")
uiOutput("stats_results_ui")
```

### LMM EXTRA

#### Tables (for LMM)

##### Fixed effects {data-height=500}

```{r}
uiOutput("lmm_assumption_button_ui")
```

```{r}
tableOutput("fixed_effects_table")
```

##### Random effects {data-height=500}
```{r}
tableOutput("random_effects_table")
```

##### Post-hoc tests {data-height=500}

```{r}
checkboxInput("force_posthoc", "Force Post-Hoc Analysis (show all effects)", value = TRUE)
checkboxInput("filter_posthoc", "Filter Post-Hoc Results (show only meaningful comparisons)", value = TRUE)
checkboxInput("paired_ttest", "Use Paired t-test instead of emmeans", value = FALSE)
```

```{r}
conditionalPanel(
  condition = "input.paired_ttest == true",
  numericInput("num_tests",
    label = "Number of Comparisons (for Bonferroni correction):",
    value = 1, # Default value
    min = 1
  ), # Minimum value (must be at least one test)
  helpText("Click 'Check assumptions' in the table below to inspect diagnostics for each paired comparison.")
)
```

```{r}
conditionalPanel(
  condition = "input.paired_ttest == false",
  selectizeInput("posthoc_correction", "Post-hoc correction method",
    choices = c("tukey", "scheffe", "sidak", "bonferroni", "holm", "hochberg", "hommel", "BH", "BY", "fdr", "none"),
    selected = "tukey", multiple = FALSE
  ),
  helpText("Tukey's HSD is recommended for pairwise comparisons. Other methods may be more or less conservative.")
)
```

```{r}
tableOutput("post_hoc_table")
```

```{r, context="server"}
# Source statistical utility functions
source("source/stats_utils.R", local = TRUE)

# Reactive values for t-test assumption checking
ttest_assumption_lookup <- reactiveVal(list())
ttest_assumption_state <- reactiveVal(NULL)

############ Getting and setting data
get_stats_data <- reactive({
  if (input$getSummarizedData_stats) {
    dt <- get_mu_dyn_long()
    if (input$averageData_stats) {
      dt <- summarize_across_conditions(dt)
    }
  } else {
    dt <- filteredParams()
  }

  # Handle empty data case
  if (!is_stats_data_valid(dt)) {
    return(handle_invalid_stats_data())
  }

  # Apply reference levels so the column names match what the selectors expect
  dt <- apply_reference_levels(dt)
  dt
})

# Helper that tells whether a dependent variable is selected AND exists in data
dep_var_valid <- reactive({
  data <- get_stats_data()
  is_dep_var_valid(input$depVar, data)
})

# Create dynamic observers for variable selection
create_dynamic_variable_observer(
  data_reactive = get_stats_data,
  input_id = "depVar",
  column_filter = function(x) TRUE, # All columns
  exclude_patterns = NULL,
  default_choice = "task.dist_to_escape_ratio_mean", # "stepWidths.sd",
  fallback_choices = NULL,
  multiple = FALSE,
  input = input
)

# Default variables more appropriate for the current experiment
defaultIndepVars <- c("condition")

create_dynamic_variable_observer(
  data_reactive = get_stats_data,
  input_id = "indepInterVars",
  column_filter = function(x) TRUE, # All columns
  exclude_patterns = NULL,
  default_choice = defaultIndepVars,
  fallback_choices = NULL,
  multiple = TRUE,
  input = input
)

create_dynamic_variable_observer(
  data_reactive = get_stats_data,
  input_id = "indepVars",
  column_filter = function(x) TRUE, # All columns
  exclude_patterns = NULL,
  default_choice = defaultIndepVars,
  fallback_choices = NULL,
  multiple = TRUE,
  input = input
)


# ----------------  APPLY MODEL  ----------------
get_lmer <- reactive({
  req(dep_var_valid()) # ← stop early but quietly if no dep-var

  data <- get_stats_data()
  validate_ready_for_lmm(data)

  # Apply transformation to dependent variable if selected
  if (input$depVarTransform == "log10") {
    # Check if all values are positive for log10 transformation
    dep_var_values <- data[[input$depVar]]
    if (any(dep_var_values <= 0, na.rm = TRUE)) {
      showNotification("Warning: Some values are <= 0. Cannot apply log10 transformation. Consider adding a constant or using a different transformation.", type = "warning")
      return(NULL)
    }
    # Apply log10 transformation
    data[[input$depVar]] <- log10(data[[input$depVar]])
  }

  doCustom <- input$useCustomModel && !is.null(input$customModel) && nzchar(input$customModel)
  if (doCustom) {
    formula <- as.formula(paste(input$depVar, "~", input$customModel))
  } else {
    formula <- build_lmm_formula(input$depVar, input$indepInterVars, input$indepVars)
  }

  if (input$doCentering) {
    data <- center_predictors(data, formula, input$depVar, input$doScaling)
  }

  fit_lmm(data, formula)
})

# ----------------  LMM OUTPUTS ----------------
output$stats_results_ui <- renderUI({
  verbatimTextOutput("lmm_text")
})

output$lmm_text <- renderPrint({
  lmm <- get_lmer()
  if (is.null(lmm)) {
    cat("Model could not be fitted. Check for errors above.\n")
    return()
  }

  results <- summary(lmm)

  # Show transformation information
  if (input$depVarTransform != "none") {
    cat("TRANSFORMATION APPLIED:\n")
    cat("Dependent variable transformation:", input$depVarTransform, "\n")
    cat("Note: All results are based on the transformed variable.\n\n")
  }

  # Summarize the model
  cat("\nLMM:\n")
  print(lmm)
  cat("\nRESULTS:\n")
  print(results)

  # Print AIC and BIC
  aic_value <- AIC(lmm)
  bic_value <- BIC(lmm)
  log_likelihood <- logLik(lmm)
  deviance <- deviance(lmm)
  r_squared <- MuMIn::r.squaredGLMM(lmm)

  cat("\nModel fit statistics:\n")
  cat("AIC:", aic_value, "\n")
  cat("BIC:", bic_value, "\n")
  cat("Log-likelihood:", log_likelihood, "\n")
  cat("Deviance:", deviance, "\n")
  cat("Marginal R-squared:", r_squared[1], "\n")
  cat("Conditional R-squared:", r_squared[2], "\n")

  # Add interpretation guidance for model fit statistics
  cat("\nModel Fit Interpretation:\n")
  cat("- AIC (Akaike Information Criterion): Lower values indicate better model fit\n")
  cat("- BIC (Bayesian Information Criterion): Lower values indicate better model fit\n")
  cat("- Log-likelihood: Higher values indicate better model fit\n")
  cat("- Deviance: Lower values indicate better model fit\n")
  cat("- R-squared: Higher values indicate more variance explained by the model\n")
  cat("  * Marginal R-squared: Variance explained by fixed effects only\n")
  cat("  * Conditional R-squared: Variance explained by both fixed and random effects\n")

  # Calculate and print VIF
  cat("\nVariance Inflation Factors (VIF):\n")
  tryCatch(
    {
      vif_values <- car::vif(lmm)
      print(vif_values)
    },
    error = function(e) {
      cat("VIF calculation failed:", e$message, "\n")
    }
  )

  cat("\nChecking Singularity:...\n")
  cat("isSingular:", isSingular(lmm, tol = 1e-4), "\n")
})

output$fixed_effects_table <- renderTable(
  {
    req(dep_var_valid()) # skip rendering until ready
    lmm <- get_lmer()
    results <- summary(lmm)
    fixed_effects <- results$coefficients

    # Calculate effect sizes
    residual_sd <- sigma(lmm)
    fixed_effects_df <- as.data.frame(fixed_effects)
    fixed_effects_df$EffectSize <- fixed_effects_df$Estimate / residual_sd

    # Adjust p-values for multiple comparisons using the selected correction method
    fixed_effects_df$AdjustedP <- p.adjust(fixed_effects_df[["Pr(>|t|)"]], method = input$correctionMethod)

    # Convert to a data frame for rendering and include row names
    fixed_effects_df <- cbind(Effect = rownames(fixed_effects_df), fixed_effects_df)
    rownames(fixed_effects_df) <- NULL

    # Format numbers and make significant p-values bold
    fixed_effects_df <- set_digits_with_bold_pvalues(fixed_effects_df, "AdjustedP")

    fixed_effects_df
  },
  rownames = TRUE,
  sanitize.text.function = function(x) x
)


output$random_effects_table <- renderTable(
  {
    req(dep_var_valid())
    lmm <- get_lmer()
    random_effects <- as.data.frame(VarCorr(lmm))

    # Clean up the random effects table
    random_effects_df <- cbind(Effect = rownames(random_effects), random_effects)
    rownames(random_effects_df) <- NULL

    # Select only relevant columns
    random_effects_df <- random_effects_df[, c("Effect", "grp", "vcov", "sdcor")]

    # Optionally rename columns for clarity
    colnames(random_effects_df) <- c("Effect", "Group", "Variance", "Standard Deviation")

    random_effects_df <- set_digits(random_effects_df)

    random_effects_df
  },
  rownames = TRUE
)

output$post_hoc_table <- renderTable(
  {
    req(dep_var_valid())
    data <- get_stats_data()
    lmm <- get_lmer()

    # Prepare analysis (use posthoc_correction for emmeans, not correctionMethod which is for fixed effects)
    lmm_posthoc <- prepare_posthoc_analysis(lmm, data, input$indepInterVars, input$indepVars, input$force_posthoc, input$posthoc_correction)
    if (is.null(lmm_posthoc)) {
      return(data.frame(Message = "No significant main or interaction effects found."))
    }

    # Choose method based on paired_ttest input
    if (input$paired_ttest) {
      res <- compute_paired_ttest_table(lmm_posthoc, data, input$depVar, input$num_tests)

      # Store assumption lookup data and add assumption buttons
      assumption_lookup <- attr(res, "assumption_lookup")
      ttest_assumption_lookup(assumption_lookup)

      # Add assumption check buttons if we have valid results and remove AssumptionID
      if (!"Message" %in% names(res)) {
        if ("AssumptionID" %in% names(res)) {
          assumption_ids <- res$AssumptionID
          res$AssumptionID <- NULL # Remove ID column from display
          res$Assumptions <- sapply(assumption_ids, build_assumption_button)
        }
      }
    } else {
      res <- lmm_posthoc$combined$df
    }

    p_format_names <- c("p_value", "p.value", "corrected_p") # what column names to format based on value < 0.05
    postprocess_posthoc_results(res, input$filter_posthoc, p_format_names)
  },
  sanitize.text.function = function(x) x,
  escape = FALSE
)

# T-test assumption checking observer
observeEvent(input$ttest_assumption_row, {
  lookup <- ttest_assumption_lookup()
  info <- lookup[[input$ttest_assumption_row]]
  if (is.null(info)) {
    showNotification("Assumption diagnostics unavailable for this comparison.", type = "error")
    return()
  }

  ttest_assumption_state(info)

  showModal(modalDialog(
    title = "Paired t-test assumption diagnostics",
    uiOutput("ttest_assumption_details"),
    plotOutput("ttest_assumption_hist", height = 250),
    plotOutput("ttest_assumption_qq", height = 250),
    plotOutput("ttest_assumption_box", height = 250),
    size = "l",
    easyClose = TRUE,
    footer = modalButton("Close")
  ))
})

# LMM assumption button
output$lmm_assumption_button_ui <- renderUI({
  req(dep_var_valid())
  HTML(build_lmm_assumption_button())
})

# LMM assumption checking observer
observeEvent(input$show_lmm_assumptions, {
  req(dep_var_valid())

  showModal(modalDialog(
    title = "Linear Mixed Model (LMM) Assumption Diagnostics",
    tags$div(
      tags$h4("How to interpret these plots:"),
      tags$ul(
        tags$li(tags$strong("QQ Plot:"), " Points should fall approximately along the diagonal line. Deviations suggest non-normal residuals."),
        tags$li(tags$strong("Residuals vs Fitted:"), " Look for random scatter around zero. Patterns suggest heteroscedasticity or non-linearity."),
        tags$li(tags$strong("Scale-Location:"), " Look for a horizontal line with equally spread points. Deviations suggest non-constant variance (heteroscedasticity)."),
        tags$li(tags$strong("Residuals vs Leverage:"), " Check for influential cases. Points outside Cook's distance lines are potential outliers that may unduly influence the model.")
      ),
      tags$p("For more detailed interpretation, please refer to statistical literature or consult a statistician.")
    ),
    plotOutput("lmm_assumption_qq", height = 250),
    plotOutput("lmm_assumption_residuals_fitted", height = 250),
    plotOutput("lmm_assumption_scale_location", height = 250),
    plotOutput("lmm_assumption_residuals_leverage", height = 250),
    size = "l",
    easyClose = TRUE,
    footer = modalButton("Close")
  ))
})

# LMM assumption modal plots
output$lmm_assumption_qq <- renderPlot({
  req(dep_var_valid())
  lmm <- get_lmer()
  qqnorm(resid(lmm), main = "QQ Plot of Residuals")
  qqline(resid(lmm), col = "blue")
})

output$lmm_assumption_residuals_fitted <- renderPlot({
  req(dep_var_valid())
  lmm <- get_lmer()
  plot(fitted(lmm), resid(lmm),
    xlab = "Fitted values",
    ylab = "Residuals",
    main = "Residuals vs Fitted"
  )
  abline(h = 0, col = "red")
})

output$lmm_assumption_scale_location <- renderPlot({
  req(dep_var_valid())
  lmm <- get_lmer()
  sqrt_resid <- sqrt(abs(resid(lmm)))
  plot(fitted(lmm), sqrt_resid,
    xlab = "Fitted values",
    ylab = "√|Standardized residuals|",
    main = "Scale-Location Plot"
  )
  abline(h = mean(sqrt_resid, na.rm = TRUE), col = "red")
})

output$lmm_assumption_residuals_leverage <- renderPlot({
  req(dep_var_valid())
  lmm <- get_lmer()
  leverage <- hatvalues(lmm)
  cooksd <- cooks.distance(lmm)
  plot(leverage, resid(lmm),
    xlab = "Leverage",
    ylab = "Residuals",
    main = "Residuals vs Leverage"
  )
  abline(h = 0, col = "red")
  # Highlight influential points
  influential <- cooksd > 4 / (length(cooksd) - length(coef(lmm)))
  points(leverage[influential], resid(lmm)[influential], pch = 20, col = "red", cex = 1.2)
})

# Modal content outputs for t-test assumptions
output$ttest_assumption_details <- renderUI({
  info <- ttest_assumption_state()
  req(info)
  tagList(
    tags$div(
      tags$h4("Comparison Details:"),
      tags$p(tags$strong("Effect:"), info$effect),
      tags$p(tags$strong("Contrast:"), info$contrast),
      tags$p(tags$strong("Pairs used:"), info$n_pairs),
      tags$p(
        tags$strong("Levels compared:"),
        sprintf(
          "%s  vs  %s",
          paste(info$left_levels, collapse = " × "),
          paste(info$right_levels, collapse = " × ")
        )
      )
    ),
    tags$div(
      tags$h4("How to interpret these plots:"),
      tags$ul(
        tags$li(tags$strong("Histogram of Differences:"), " Should be roughly symmetric and bell-shaped, centered around zero. Skewness or multiple peaks may indicate violations of normality."),
        tags$li(tags$strong("Q-Q Plot of Differences:"), " Points should fall approximately along the diagonal line (blue). Systematic deviations suggest the differences are not normally distributed."),
        tags$li(tags$strong("Boxplot of Differences:"), " Check for extreme outliers (points beyond the whiskers). Outliers can affect the validity of the paired t-test and should be investigated.")
      ),
      tags$p(tags$strong("Note:"), " The paired t-test assumes that the differences between paired observations are normally distributed. If these assumptions are violated, consider non-parametric alternatives like the Wilcoxon signed-rank test.")
    )
  )
})

output$ttest_assumption_hist <- renderPlot({
  info <- ttest_assumption_state()
  req(info)
  diffs <- info$differences
  if (length(diffs) < 2) {
    plot.new()
    text(0.5, 0.5, "Not enough paired observations\nto plot diagnostics.", cex = 1.1, col = "red")
    return()
  }
  hist(diffs,
    main = "Histogram of Paired Differences",
    xlab = "Differences (Right - Left)", col = "lightblue", border = "white",
    breaks = max(5, min(15, length(diffs) / 3))
  )
  # Add normal curve overlay
  x_seq <- seq(min(diffs), max(diffs), length.out = 100)
  y_seq <- dnorm(x_seq, mean(diffs), sd(diffs))
  y_seq <- y_seq * length(diffs) * diff(range(diffs)) / length(x_seq)
  lines(x_seq, y_seq, col = "red", lwd = 2)
})

output$ttest_assumption_qq <- renderPlot({
  info <- ttest_assumption_state()
  req(info)
  diffs <- info$differences
  if (length(diffs) < 2) {
    plot.new()
    text(0.5, 0.5, "Not enough paired observations\nto plot diagnostics.", cex = 1.1, col = "red")
    return()
  }
  qqnorm(diffs, main = "Q-Q Plot of Differences")
  qqline(diffs, col = "blue", lwd = 2)
})

output$ttest_assumption_box <- renderPlot({
  info <- ttest_assumption_state()
  req(info)
  diffs <- info$differences
  if (length(diffs) < 2) {
    plot.new()
    text(0.5, 0.5, "Not enough paired observations\nto plot diagnostics.", cex = 1.1, col = "red")
    return()
  }
  boxplot(diffs,
    main = "Boxplot of Differences",
    ylab = "Differences (Right - Left)",
    col = "lightblue", border = "darkblue"
  )
  abline(h = 0, col = "red", lty = 2)
  # Add mean line
  abline(h = mean(diffs), col = "green", lwd = 2)
  legend("topright", c("Zero line", "Mean"),
    col = c("red", "green"),
    lty = c(2, 1), lwd = c(1, 2), cex = 0.8
  )
})
```

