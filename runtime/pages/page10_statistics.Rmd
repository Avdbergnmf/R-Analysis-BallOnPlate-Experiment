### Options

#### Dependent Variable
```{r}
selectizeInput("depVar", "Dependent variable",
  choices = NULL, selected = NULL, multiple = FALSE
)

selectizeInput("depVarTransform", "Transform dependent variable",
  choices = c("None" = "none", "Log10" = "log10", "Logit" = "logit"),
  selected = "none", multiple = FALSE
)
```

```{r}
tags$hr(style = "margin-top: 10px; margin-bottom: 10px;")
```

#### Independent Variables
```{r}
selectizeInput("indepInterVars", "Independent variable(s) (interactions)",
  choices = NULL, selected = NULL, multiple = TRUE
)

selectizeInput("indepVars", "Independent variable(s) (add to model)",
  choices = NULL, selected = NULL, multiple = TRUE
)
```

```{r}
tags$hr(style = "margin-top: 10px; margin-bottom: 10px;")
```

#### Data Options
```{r}
checkboxInput("getSummarizedData_stats", "Use summarized data", value = TRUE)
checkboxInput("averageData_stats", "Average data across condition", value = FALSE)
checkboxInput("diffData_stats", "Calculate difference + means per participant", value = FALSE)
```

```{r}
tags$hr(style = "margin-top: 10px; margin-bottom: 10px;")
```

#### Model Settings
```{r}
textInput("customModel", "Custom Model Formula: dependent_variable ~ ", value = "condition * phase + (1 + taskNum | participant)")

checkboxInput("useCustomModel", "Use custom model (above)", value = TRUE)
checkboxInput("doCentering", "Center numerical variables", value = TRUE)
checkboxInput("doScaling", "Also scale (standardize) variables", value = FALSE)

selectizeInput("correctionMethod", "Multiple comparison correction (fixed effects)",
  choices = general_correction_choices,
  selected = "holm", multiple = FALSE
)
```

```{r}
tags$hr(style = "margin-top: 10px; margin-bottom: 10px;")
```

#### Reference Levels
```{r}
selectizeInput("refLevelCondition", "Reference level for condition",
  choices = NULL, selected = NULL, multiple = FALSE
)

selectizeInput("refLevelPhase", "Reference level for phase",
  choices = NULL, selected = NULL, multiple = FALSE
)
```

```{r}
bsTooltip("depVarTransform",
  "Apply transformation to the dependent variable before analysis. Log10 transformation can help with skewed data. Logit transformation is for proportions (values between 0 and 1).",
  placement = "right",
  trigger = "hover"
)
bsTooltip("refLevelCondition",
  "Select the reference level (baseline) for condition comparisons. Other conditions will be compared against this level. Auto-selects the default from initialization.R.",
  placement = "right",
  trigger = "hover"
)
bsTooltip("refLevelPhase",
  "Select the reference level (baseline) for phase comparisons. Other phases will be compared against this level. Auto-selects the default from initialization.R.",
  placement = "right",
  trigger = "hover"
)
bsTooltip("indepInterVars",
  "These independent variables are also multiplied with eachother (including the interaction terms).",
  placement = "right",
  trigger = "hover"
)
bsTooltip("indepVars",
  "These independent variables are not multiplied with eachother.",
  placement = "right",
  trigger = "hover"
)
```

```{r}
bsTooltip("averageData_stats",
  "Make sure to do this when looking at questionnaire data as the dependent variable.",
  placement = "right",
  trigger = "hover"
)
```

```{r}
bsTooltip("force_posthoc",
  "When checked, post-hoc tests will be performed for all effects, not just significant ones.",
  placement = "right",
  trigger = "hover"
)
```

```{r}
bsTooltip("filter_posthoc",
  "When checked, only shows comparisons where at least one level matches between groups (e.g., same condition or same phase).",
  placement = "right",
  trigger = "hover"
)
```

Column
--------------------------------------------

### Statistics Results  {data-height=500}
In this page we ran all of our statistical tests. Select the data in the sidebar, and choose the test settings in the options on the left. Be sure to check the assumptions of the test below. Using the custom formula box disables use of the other independent variable selection boxes.
```{r}
# verbatimTextOutput("stats_results")
uiOutput("stats_results_ui")
```

### LMM EXTRA

#### Tables (for LMM)

##### Fixed effects {data-height=500}

```{r}
uiOutput("lmm_assumption_button_ui")
```

```{r}
tableOutput("fixed_effects_table")
```

##### Random effects {data-height=500}
```{r}
tableOutput("random_effects_table")
```

##### Post-hoc tests {data-height=500}

```{r}
checkboxInput("force_posthoc", "Force Post-Hoc Analysis (show all effects)", value = TRUE)
checkboxInput("filter_posthoc", "Filter Post-Hoc Results (show only meaningful comparisons)", value = TRUE)
checkboxInput("paired_ttest", "Use Paired t-test instead of emmeans", value = FALSE)
```

```{r}
conditionalPanel(
  condition = "input.paired_ttest == true",
  numericInput("num_tests",
    label = "Number of Comparisons (for Bonferroni correction):",
    value = 1, # Default value
    min = 1
  ), # Minimum value (must be at least one test)
  helpText("Click 'Check assumptions' in the table below to inspect diagnostics for each paired comparison.")
)
```

```{r}
conditionalPanel(
  condition = "input.paired_ttest == false",
  selectizeInput("posthoc_correction", "Post-hoc correction method",
    choices = c("tukey", "scheffe", "sidak", general_correction_choices),
    selected = "tukey", multiple = FALSE
  ),
  helpText("Tukey's HSD is recommended for pairwise comparisons. Other methods may be more or less conservative.")
)
```

```{r}
uiOutput("did_button_ui")
```

```{r}
tableOutput("post_hoc_table")
```

```{r, context="server"}
# Load stats feature module on-demand
stats <- load_feature("stats")

# Reactive values for t-test assumption checking
ttest_assumption_lookup <- reactiveVal(list())
ttest_assumption_state <- reactiveVal(NULL)

############ Getting and setting data
get_stats_data <- reactive({
  if (input$getSummarizedData_stats) {
    dt <- get_mu_dyn_long()
    if (input$averageData_stats) {
      dt <- summarize_across_conditions(dt)
    }
  } else {
    dt <- filteredParams()
  }

  # Handle empty data case
  if (!stats$validate_stats_data(dt)) {
    return(stats$handle_invalid_data())
  }

  # Apply reference levels so the column names match what the selectors expect
  dt <- stats$prepare_stats_dataset(input$useSummarized, input$averageAcross)
  dt
})

# Helper that tells whether a dependent variable is selected AND exists in data
dep_var_valid <- reactive({
  data <- get_stats_data()
  is_dep_var_valid(input$depVar, data)
})

# Create dynamic observers for variable selection
create_dynamic_variable_observer(
  data_reactive = get_stats_data,
  input_id = "depVar",
  column_filter = function(x) TRUE, # All columns
  exclude_patterns = NULL,
  default_choice = "task.dist_to_escape_ratio_mean", # "stepWidths.sd",
  fallback_choices = NULL,
  multiple = FALSE,
  input = input
)

# Default variables more appropriate for the current experiment
defaultIndepVars <- c("condition")

create_dynamic_variable_observer(
  data_reactive = get_stats_data,
  input_id = "indepInterVars",
  column_filter = function(x) TRUE, # All columns
  exclude_patterns = NULL,
  default_choice = defaultIndepVars,
  fallback_choices = NULL,
  multiple = TRUE,
  input = input
)

create_dynamic_variable_observer(
  data_reactive = get_stats_data,
  input_id = "indepVars",
  column_filter = function(x) TRUE, # All columns
  exclude_patterns = NULL,
  default_choice = defaultIndepVars,
  fallback_choices = NULL,
  multiple = TRUE,
  input = input
)

# Dynamic observers for reference level selection
observe({
  data <- get_stats_data()

  if ("condition" %in% names(data)) {
    available_conditions <- unique(data$condition)

    # Get default from reference_levels or use first value
    default_ref <- if (exists("reference_levels") && "condition" %in% names(reference_levels)) {
      ref <- reference_levels$condition
      if (ref %in% available_conditions) ref else available_conditions[1]
    } else {
      available_conditions[1]
    }

    updateSelectizeInput(session, "refLevelCondition",
      choices = available_conditions,
      selected = default_ref
    )
  }

  if ("phase" %in% names(data)) {
    available_phases <- unique(data$phase)

    # Get default from reference_levels or use first value
    default_ref <- if (exists("reference_levels") && "phase" %in% names(reference_levels)) {
      ref <- reference_levels$phase
      if (ref %in% available_phases) ref else available_phases[1]
    } else {
      available_phases[1]
    }

    updateSelectizeInput(session, "refLevelPhase",
      choices = available_phases,
      selected = default_ref
    )
  }
})

# ----------------  APPLY MODEL  ----------------
get_lmer <- reactive({
  req(dep_var_valid()) # ← stop early but quietly if no dep-var

  data <- get_stats_data()
  # Validation is now handled in fit_mixed_model

  # Apply custom reference levels if specified
  if (!is.null(input$refLevelCondition) && nzchar(input$refLevelCondition)) {
    data <- stats$set_reference_level(data, "condition", input$refLevelCondition)
  }
  if (!is.null(input$refLevelPhase) && nzchar(input$refLevelPhase)) {
    data <- stats$set_reference_level(data, "phase", input$refLevelPhase)
  }

  # Apply transformation to dependent variable if selected
  data <- stats$transform_dependent_variable(data, input$depVar, input$depVarTransform)
  if (is.null(data)) {
    return(NULL)
  }

  doCustom <- input$useCustomModel && !is.null(input$customModel) && nzchar(input$customModel)
  if (doCustom) {
    formula <- as.formula(paste(input$depVar, "~", input$customModel))
  } else {
    formula <- stats$create_lmm_formula(input$depVar, input$indepInterVars, input$indepVars)
  }

  # Centering is now handled in fit_mixed_model

  stats$fit_mixed_model(data, formula, input$depVar, input$doCentering, input$doScaling)
})

# ----------------  LMM OUTPUTS ----------------
output$stats_results_ui <- renderUI({
  verbatimTextOutput("lmm_text")
})

output$lmm_text <- renderPrint({
  lmm <- get_lmer()
  if (is.null(lmm)) {
    cat("Model could not be fitted. Check for errors above.\n")
    return()
  }

  results <- summary(lmm)

  # Show reference level information
  cat("REFERENCE LEVELS:\n")
  if (!is.null(input$refLevelCondition) && nzchar(input$refLevelCondition)) {
    cat("Condition reference level:", input$refLevelCondition, "\n")
  }
  if (!is.null(input$refLevelPhase) && nzchar(input$refLevelPhase)) {
    cat("Phase reference level:", input$refLevelPhase, "\n")
  }
  cat("\n")

  # Show transformation information
  if (input$depVarTransform != "none") {
    cat("TRANSFORMATION APPLIED:\n")
    cat("Dependent variable transformation:", input$depVarTransform, "\n")
    cat("Note: All results are based on the transformed variable.\n\n")
  }

  # Summarize the model
  cat("\nLMM:\n")
  print(lmm)
  cat("\nRESULTS:\n")
  print(results)

  # Print AIC and BIC
  aic_value <- AIC(lmm)
  bic_value <- BIC(lmm)
  log_likelihood <- logLik(lmm)
  deviance <- deviance(lmm)
  r_squared <- MuMIn::r.squaredGLMM(lmm)

  cat("\nModel fit statistics:\n")
  cat("AIC:", aic_value, "\n")
  cat("BIC:", bic_value, "\n")
  cat("Log-likelihood:", log_likelihood, "\n")
  cat("Deviance:", deviance, "\n")
  cat("Marginal R-squared:", r_squared[1], "\n")
  cat("Conditional R-squared:", r_squared[2], "\n")

  # Add interpretation guidance for model fit statistics
  cat("\nModel Fit Interpretation:\n")
  cat("- AIC (Akaike Information Criterion): Lower values indicate better model fit\n")
  cat("- BIC (Bayesian Information Criterion): Lower values indicate better model fit\n")
  cat("- Log-likelihood: Higher values indicate better model fit\n")
  cat("- Deviance: Lower values indicate better model fit\n")
  cat("- R-squared: Higher values indicate more variance explained by the model\n")
  cat("  * Marginal R-squared: Variance explained by fixed effects only\n")
  cat("  * Conditional R-squared: Variance explained by both fixed and random effects\n")

  # Calculate and print VIF
  cat("\nVariance Inflation Factors (VIF):\n")
  tryCatch(
    {
      vif_values <- car::vif(lmm)
      print(vif_values)
    },
    error = function(e) {
      cat("VIF calculation failed:", e$message, "\n")
    }
  )

  cat("\nChecking Singularity:...\n")
  cat("isSingular:", isSingular(lmm, tol = 1e-4), "\n")
})

output$fixed_effects_table <- renderTable(
  {
    req(dep_var_valid()) # skip rendering until ready
    lmm <- get_lmer()
    results <- summary(lmm)
    fixed_effects <- results$coefficients

    # Calculate effect sizes
    residual_sd <- sigma(lmm)
    fixed_effects_df <- as.data.frame(fixed_effects)
    fixed_effects_df$EffectSize <- fixed_effects_df$Estimate / residual_sd

    # Adjust p-values for multiple comparisons using the selected correction method
    fixed_effects_df$AdjustedP <- p.adjust(fixed_effects_df[["Pr(>|t|)"]], method = input$correctionMethod)

    # Convert to a data frame for rendering and include row names
    fixed_effects_df <- cbind(Effect = rownames(fixed_effects_df), fixed_effects_df)
    rownames(fixed_effects_df) <- NULL

    # Format numbers and make significant p-values bold
    fixed_effects_df <- set_digits_with_bold_pvalues(fixed_effects_df, "AdjustedP")

    fixed_effects_df
  },
  rownames = TRUE,
  sanitize.text.function = function(x) x
)


output$random_effects_table <- renderTable(
  {
    req(dep_var_valid())
    lmm <- get_lmer()
    random_effects <- as.data.frame(VarCorr(lmm))

    # Clean up the random effects table
    random_effects_df <- cbind(Effect = rownames(random_effects), random_effects)
    rownames(random_effects_df) <- NULL

    # Select only relevant columns
    random_effects_df <- random_effects_df[, c("Effect", "grp", "vcov", "sdcor")]

    # Optionally rename columns for clarity
    colnames(random_effects_df) <- c("Effect", "Group", "Variance", "Standard Deviation")

    random_effects_df <- set_digits(random_effects_df)

    random_effects_df
  },
  rownames = TRUE
)

output$post_hoc_table <- renderTable(
  {
    req(dep_var_valid())
    lmm <- get_lmer()

    # Get the same processed data that was used for the model
    data <- get_stats_data()

    # Apply same reference levels as in get_lmer()
    if (!is.null(input$refLevelCondition) && nzchar(input$refLevelCondition)) {
      data <- stats$set_reference_level(data, "condition", input$refLevelCondition)
    }
    if (!is.null(input$refLevelPhase) && nzchar(input$refLevelPhase)) {
      data <- stats$set_reference_level(data, "phase", input$refLevelPhase)
    }

    # Apply same transformation as in get_lmer()
    data <- stats$transform_dependent_variable(data, input$depVar, input$depVarTransform)
    if (is.null(data)) {
      return(data.frame(Message = "Transformation failed. Cannot perform post-hoc analysis."))
    }

    # Prepare analysis (use posthoc_correction for emmeans, not correctionMethod which is for fixed effects)
    posthoc_results <- stats$run_posthoc_analysis(lmm, data, input$indepInterVars, input$indepVars, input$force_posthoc, input$posthoc_correction)
    if (is.null(posthoc_results$results)) {
      return(data.frame(Message = "No significant main or interaction effects found."))
    }
    
    # Create lmm_posthoc structure for compatibility with existing code
    lmm_posthoc <- list(
      combined = list(df = posthoc_results$results),
      posthoc_results = posthoc_results$metadata$posthoc_results,
      all_indep_vars = posthoc_results$metadata$all_indep_vars
    )

    # Choose method based on paired_ttest input
    if (input$paired_ttest) {
      res <- stats$run_paired_ttest_analysis(lmm_posthoc, data, input$depVar, input$num_tests)

      # Store assumption lookup data and add assumption buttons
      assumption_lookup <- attr(res, "assumption_lookup")
      ttest_assumption_lookup(assumption_lookup)

      # Add assumption check buttons if we have valid results and remove AssumptionID
      if (!"Message" %in% names(res)) {
        if ("AssumptionID" %in% names(res)) {
          assumption_ids <- res$AssumptionID
          res$AssumptionID <- NULL # Remove ID column from display
          res$Assumptions <- sapply(assumption_ids, stats$create_assumption_button)
        }
      }
    } else {
      res <- lmm_posthoc$combined$df
    }

    p_format_names <- c("p_value", "p.value", "corrected_p") # what column names to format based on value < 0.05
    postprocess_posthoc_results(res, input$filter_posthoc, p_format_names)
  },
  sanitize.text.function = function(x) x,
  escape = FALSE
)

# T-test assumption checking observer
observeEvent(input$ttest_assumption_row, {
  lookup <- ttest_assumption_lookup()
  info <- lookup[[input$ttest_assumption_row]]
  if (is.null(info)) {
    showNotification("Assumption diagnostics unavailable for this comparison.", type = "error")
    return()
  }

  ttest_assumption_state(info)

  showModal(modalDialog(
    title = "Paired t-test assumption diagnostics",
    uiOutput("ttest_assumption_details"),
    plotOutput("ttest_assumption_hist", height = 250),
    plotOutput("ttest_assumption_qq", height = 250),
    plotOutput("ttest_assumption_box", height = 250),
    size = "l",
    easyClose = TRUE,
    footer = modalButton("Close")
  ))
})

# DiD button UI
output$did_button_ui <- renderUI({
  req(dep_var_valid())
  HTML(stats$create_did_button())
})

# LMM assumption button
output$lmm_assumption_button_ui <- renderUI({
  req(dep_var_valid())
  HTML(stats$create_lmm_assumption_button())
})

# DiD analysis observer
observeEvent(input$show_did_analysis, {
  req(dep_var_valid())

  lmm <- get_lmer()
  data <- get_stats_data()

  if (is.null(lmm)) {
    showNotification("Model could not be fitted. Please check your model settings.", type = "error")
    return()
  }

  # Compute DiD analysis (uses Kenward-Roger df and selected correction method)
  did_results <- stats$run_did_analysis(lmm, data, input$correctionMethod)

  # Check if we have valid results
  if (!is.null(did_results$message)) {
    showNotification(did_results$message, type = "warning", duration = 10)
    return()
  }

  # Format the results for display
  within_cond_display <- did_results$within_condition
  within_phase_display <- did_results$within_phase
  did_display <- did_results$did
  baseline_used <- did_results$baseline_used

  if (!is.null(within_cond_display)) {
    within_cond_display <- set_digits_with_bold_pvalues(within_cond_display, "p_adjusted", digits = 4)
  }
  if (!is.null(within_phase_display)) {
    within_phase_display <- set_digits_with_bold_pvalues(within_phase_display, "p_adjusted", digits = 4)
  }
  if (!is.null(did_display)) {
    did_display <- set_digits_with_bold_pvalues(did_display, "p_adjusted", digits = 4)
  }

  # Show modal with results
  showModal(
    modalDialog(
      tags$head(tags$style(HTML("
        .modal-dialog { max-width: 90%; width: 90%; }
        .modal-body { overflow-x: auto; }
      "))),
      title = "Difference-in-Differences (DiD) Analysis",
      tags$div(
        tags$h4("Overview:"),
        tags$p("This analysis compares how changes from baseline phase differ between conditions."),
        tags$p(tags$strong("Baseline phase used:"), baseline_used),
        tags$hr(),
        tags$h5("Statistical Methods:"),
        tags$ul(
          tags$li(tags$strong("Degrees of Freedom:"), " Kenward-Roger approximation (more accurate for small samples and complex random effects structures)"),
          tags$li(tags$strong("Multiple Comparison Correction:"), paste("Selected method:", input$correctionMethod)),
          tags$li(tags$strong("Confidence Intervals:"), " 95% CIs based on the t-distribution with Kenward-Roger df")
        ),
        tags$h5("Interpreting Estimates:"),
        tags$ul(
          tags$li(tags$strong("Within-Condition:"), " Positive = increase from baseline; Negative = decrease from baseline"),
          tags$li(tags$strong("Within-Phase:"), " Positive = condition_cmp > condition_ref; Negative = condition_cmp < condition_ref"),
          tags$li(tags$strong("DiD:"), " Positive = condition_cmp changed more (or decreased less) than condition_ref from baseline; Negative = condition_cmp changed less (or decreased more) than condition_ref")
        ),
        tags$p(tags$em("Note: Bold p-values indicate significance at α = 0.05 after correction.")),
        tags$hr()
      ),

      # Within-condition comparisons table
      if (!is.null(within_cond_display)) {
        tags$div(
          tags$h4("Within-Condition Phase Comparisons", style = "margin-top: 20px;"),
          tags$p("Each condition's change from baseline phase (used as inputs for DiD calculation)."),
          renderTable(
            {
              within_cond_display
            },
            sanitize.text.function = function(x) x,
            escape = FALSE
          ),
          tags$hr()
        )
      },

      # DiD results table
      tags$div(
        tags$h4("Difference-in-Differences Results", style = "margin-top: 20px;"),
        tags$p("Tests whether conditions differ in how they changed from baseline to each phase."),
        renderTable(
          {
            did_display
          },
          sanitize.text.function = function(x) x,
          escape = FALSE
        ),
        tags$hr()
      ),

      # Within-phase comparisons table
      if (!is.null(within_phase_display)) {
        tags$div(
          tags$h4("Within-Phase Condition Comparisons", style = "margin-top: 20px;"),
          tags$p("Pairwise comparisons between all conditions within each phase."),
          renderTable(
            {
              within_phase_display
            },
            sanitize.text.function = function(x) x,
            escape = FALSE
          )
        )
      },
      easyClose = TRUE,
      footer = modalButton("Close")
    )
  )
})

# LMM assumption checking observer
observeEvent(input$show_lmm_assumptions, {
  req(dep_var_valid())

  showModal(modalDialog(
    title = "Linear Mixed Model (LMM) Assumption Diagnostics",
    tags$div(
      tags$h4("How to interpret these plots:"),
      tags$ul(
        tags$li(tags$strong("QQ Plot:"), " Points should fall approximately along the diagonal line. Deviations suggest non-normal residuals."),
        tags$li(tags$strong("Residuals vs Fitted:"), " Look for random scatter around zero. Patterns suggest heteroscedasticity or non-linearity."),
        tags$li(tags$strong("Scale-Location:"), " Look for a horizontal line with equally spread points. Deviations suggest non-constant variance (heteroscedasticity)."),
        tags$li(tags$strong("Residuals vs Leverage:"), " Check for influential cases. Points outside Cook's distance lines are potential outliers that may unduly influence the model.")
      ),
      tags$p("For more detailed interpretation, please refer to statistical literature or consult a statistician.")
    ),
    plotOutput("lmm_assumption_qq", height = 250),
    plotOutput("lmm_assumption_residuals_fitted", height = 250),
    plotOutput("lmm_assumption_scale_location", height = 250),
    plotOutput("lmm_assumption_residuals_leverage", height = 250),
    size = "l",
    easyClose = TRUE,
    footer = modalButton("Close")
  ))
})

# LMM assumption modal plots
output$lmm_assumption_qq <- renderPlot({
  req(dep_var_valid())
  lmm <- get_lmer()
  qqnorm(resid(lmm), main = "QQ Plot of Residuals")
  qqline(resid(lmm), col = "blue")
})

output$lmm_assumption_residuals_fitted <- renderPlot({
  req(dep_var_valid())
  lmm <- get_lmer()
  plot(fitted(lmm), resid(lmm),
    xlab = "Fitted values",
    ylab = "Residuals",
    main = "Residuals vs Fitted"
  )
  abline(h = 0, col = "red")
})

output$lmm_assumption_scale_location <- renderPlot({
  req(dep_var_valid())
  lmm <- get_lmer()
  sqrt_resid <- sqrt(abs(resid(lmm)))
  plot(fitted(lmm), sqrt_resid,
    xlab = "Fitted values",
    ylab = "√|Standardized residuals|",
    main = "Scale-Location Plot"
  )
  abline(h = mean(sqrt_resid, na.rm = TRUE), col = "red")
})

output$lmm_assumption_residuals_leverage <- renderPlot({
  req(dep_var_valid())
  lmm <- get_lmer()
  leverage <- hatvalues(lmm)
  cooksd <- cooks.distance(lmm)
  plot(leverage, resid(lmm),
    xlab = "Leverage",
    ylab = "Residuals",
    main = "Residuals vs Leverage"
  )
  abline(h = 0, col = "red")
  # Highlight influential points
  influential <- cooksd > 4 / (length(cooksd) - length(coef(lmm)))
  points(leverage[influential], resid(lmm)[influential], pch = 20, col = "red", cex = 1.2)
})

# Modal content outputs for t-test assumptions
output$ttest_assumption_details <- renderUI({
  info <- ttest_assumption_state()
  req(info)
  tagList(
    tags$div(
      tags$h4("Comparison Details:"),
      tags$p(tags$strong("Effect:"), info$effect),
      tags$p(tags$strong("Contrast:"), info$contrast),
      tags$p(tags$strong("Pairs used:"), info$n_pairs),
      tags$p(
        tags$strong("Levels compared:"),
        sprintf(
          "%s  vs  %s",
          paste(info$left_levels, collapse = " × "),
          paste(info$right_levels, collapse = " × ")
        )
      )
    ),
    tags$div(
      tags$h4("How to interpret these plots:"),
      tags$ul(
        tags$li(tags$strong("Histogram of Differences:"), " Should be roughly symmetric and bell-shaped, centered around zero. Skewness or multiple peaks may indicate violations of normality."),
        tags$li(tags$strong("Q-Q Plot of Differences:"), " Points should fall approximately along the diagonal line (blue). Systematic deviations suggest the differences are not normally distributed."),
        tags$li(tags$strong("Boxplot of Differences:"), " Check for extreme outliers (points beyond the whiskers). Outliers can affect the validity of the paired t-test and should be investigated.")
      ),
      tags$p(tags$strong("Note:"), " The paired t-test assumes that the differences between paired observations are normally distributed. If these assumptions are violated, consider non-parametric alternatives like the Wilcoxon signed-rank test.")
    )
  )
})

output$ttest_assumption_hist <- renderPlot({
  info <- ttest_assumption_state()
  req(info)
  diffs <- info$differences
  if (length(diffs) < 2) {
    plot.new()
    text(0.5, 0.5, "Not enough paired observations\nto plot diagnostics.", cex = 1.1, col = "red")
    return()
  }
  hist(diffs,
    main = "Histogram of Paired Differences",
    xlab = "Differences (Right - Left)", col = "lightblue", border = "white",
    breaks = max(5, min(15, length(diffs) / 3))
  )
  # Add normal curve overlay
  x_seq <- seq(min(diffs), max(diffs), length.out = 100)
  y_seq <- dnorm(x_seq, mean(diffs), sd(diffs))
  y_seq <- y_seq * length(diffs) * diff(range(diffs)) / length(x_seq)
  lines(x_seq, y_seq, col = "red", lwd = 2)
})

output$ttest_assumption_qq <- renderPlot({
  info <- ttest_assumption_state()
  req(info)
  diffs <- info$differences
  if (length(diffs) < 2) {
    plot.new()
    text(0.5, 0.5, "Not enough paired observations\nto plot diagnostics.", cex = 1.1, col = "red")
    return()
  }
  qqnorm(diffs, main = "Q-Q Plot of Differences")
  qqline(diffs, col = "blue", lwd = 2)
})

output$ttest_assumption_box <- renderPlot({
  info <- ttest_assumption_state()
  req(info)
  diffs <- info$differences
  if (length(diffs) < 2) {
    plot.new()
    text(0.5, 0.5, "Not enough paired observations\nto plot diagnostics.", cex = 1.1, col = "red")
    return()
  }
  boxplot(diffs,
    main = "Boxplot of Differences",
    ylab = "Differences (Right - Left)",
    col = "lightblue", border = "darkblue"
  )
  abline(h = 0, col = "red", lty = 2)
  # Add mean line
  abline(h = mean(diffs), col = "green", lwd = 2)
  legend("topright", c("Zero line", "Mean"),
    col = c("red", "green"),
    lty = c(2, 1), lwd = c(1, 2), cex = 0.8
  )
})
```

